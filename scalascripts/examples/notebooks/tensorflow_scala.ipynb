{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Scala Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to load [TensorFlowScala](http://platanios.org/tensorflow_scala) into our kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(\n",
    "  // replace with linux-gpu-x86_64 on linux with nvidia gpu or with darwin-cpu-x86_64 on macOS \n",
    "  (\"org.platanios\" %% \"tensorflow\" % \"0.4.1\").withClassifier(\"linux-cpu-x86_64\"),\n",
    "  \"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.layers._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.data.image.MNISTLoader\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.Paths\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.learn._\n",
    "import org.platanios.tensorflow.api.learn.layers._\n",
    "import org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "\n",
    "import java.nio.file.Paths\n",
    "import scala.util.Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-25 22:11:45.197 [scala-interpreter-1] INFO  MNIST Data Loader - Downloading file 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'.\n",
      "2018-11-25 22:11:48.007 [scala-interpreter-1] INFO  MNIST Data Loader - Downloaded file 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'.\n",
      "2018-11-25 22:11:48.008 [scala-interpreter-1] INFO  MNIST Data Loader - Downloading file 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'.\n",
      "2018-11-25 22:11:48.114 [scala-interpreter-1] INFO  MNIST Data Loader - Downloaded file 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'.\n",
      "2018-11-25 22:11:48.114 [scala-interpreter-1] INFO  MNIST Data Loader - Downloading file 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'.\n",
      "2018-11-25 22:11:48.550 [scala-interpreter-1] INFO  MNIST Data Loader - Downloaded file 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'.\n",
      "2018-11-25 22:11:48.552 [scala-interpreter-1] INFO  MNIST Data Loader - Downloading file 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'.\n",
      "2018-11-25 22:11:48.654 [scala-interpreter-1] INFO  MNIST Data Loader - Downloaded file 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'.\n",
      "2018-11-25 22:11:48.655 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting images from file 'tmp/mnist/train-images-idx3-ubyte.gz'.\n",
      "2018-11-25 22:11:50.320 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting labels from file 'tmp/mnist/train-labels-idx1-ubyte.gz'.\n",
      "2018-11-25 22:11:50.323 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting images from file 'tmp/mnist/t10k-images-idx3-ubyte.gz'.\n",
      "2018-11-25 22:11:50.392 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting labels from file 'tmp/mnist/t10k-labels-idx1-ubyte.gz'.\n",
      "2018-11-25 22:11:50.393 [scala-interpreter-1] INFO  MNIST Data Loader - Finished loading the MNIST dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdataset\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mplatanios\u001b[39m.\u001b[32mtensorflow\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mimage\u001b[39m.\u001b[32mMNISTDataset\u001b[39m = \u001b[33mMNISTDataset\u001b[39m(\n",
       "  MNIST,\n",
       "  Tensor[UByte, [60000, 28, 28]],\n",
       "  Tensor[UByte, [60000]],\n",
       "  Tensor[UByte, [10000, 28, 28]],\n",
       "  Tensor[UByte, [10000]]\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataset = MNISTLoader.load(Paths.get(\"tmp/mnist\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display a few example images from our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzElEQVQokWNgGBzA+78nhMGERbLwP7qIKxuMxffsqzSa5FsvGEvs3xIGdGOLYIxAhn0YktthDMk/l9FMVf8mB2Memofunon/jKEsodfXJdCMtbh7Hcr6823/CzRJzcvfoCxpWX6YDSwQSpVNQU+cQZeHgdtLmCHs/tTnKO758Q8BzpigOWj7H4jE+7f/fsODgxHGMAliZ2C4eu1pRGdjI7pX4GDbPxs4GyNWRN9cwalR6sMCnHIMzv8sEBx0Y0Ne38SpUfr9Utym0gUAALXiRvo/mDSWAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAeklEQVQokWNgGNyANep/OE5Jm79/exE8JnzmkCKpycCwAKfajX+v8uGS0/71NxWnxgV//2qS6SA8khwyDEcf4pIscWR49w2XpBADw1lcVjBO/nsYpxvY/v59qoTHtZ8+45F8/RqPJG7AcvFvDIoAss4//gzqxBpECQAAd0sfL6JOTHMAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVQokWNgGEDAKNN0+9+/f9dfTQliwZDM/AsHZ7mgYnBV+gyffzMwzHvGUCViwPENTadApiKEcfPvXyEcVnN5vf/7QQCrFHfb/r9/3zthk5L33v/379+/q6UwpTi9n0Fde6eCGU1O+sDfv3//vj169Ojtv39T0CQb/v79eyHJgIGBwef73yVMqJLq/QtsBSHM9r9/WXF4hoGh7+8tzBCEgsCff9shLCZMSVsWhmu4NO76+bcAWYvN/Vi4mad//r3CDeWwMDAwMNfKtfEyMDAwMChGC7MwLMv+iqSR/S8yKOBmQAaMoQipch50JzL69P79+/fv30WNCoy43EkvAACUZ3s4Vjb6vwAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVQokcXOvyvEcRzH8aev3NVNBosiFqekrAZlVSYWRaTuBslf4C+wGE0io27ESNmUzaK+LIq6RX2LuO54dobLj76fj5XX8q7Po9f784Z/z9BOu12KU081U+OYHOivuK6qgzGbyTxaa+pFxAqXZiUWW2blECtaAw51LsR770ZzmHxtTThPgT0oBsV5nycApvQ03+zd4OYqX/jEgWl2Aag/0gj+hCYA/X3sR7CTscjat1Znds9yexxce2YNYFWXAqPqyzKUT7wuhDiS+f60/eDreGiwqWq68uOp6/u0yYXicLpVjxX/MB8UrFs7j5ILMwAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAy0lEQVQokWNgoAqY+n8WCp8JmaP3TxenJBMjmknIkvqWDO9w2ciy4O8PO1yS3H//7sJprAsDw3FcGmUu//2rh0sy6O/f5Uy4JKf9/ayPS075w9+zDAwMSodOzA/GkDT9+zeDgan4y9+/fz8Yo0tO//s3kSHy79+/f//+fS4LEUNywo9NDL4QlhgfhuS/t/p+qKaxIJjscc6cOCWZp/+Hsgrvokm+/cHBAWGdKjj9D925RRCX/j3vDBdCxC+PXDqDqcLq2Q8/o2sbIgAAO+hFsOALJnkAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36msess\u001b[39m: \u001b[32mSession\u001b[39m = org.platanios.tensorflow.api.core.client.Session@481ca54d\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mshowImage\u001b[39m\n",
       "\u001b[36mrandomImages\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mimmutable\u001b[39m.\u001b[32mIndexedSeq\u001b[39m[\u001b[32mTensor\u001b[39m[\u001b[32mUByte\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  Tensor[UByte, [28, 28, 1]],\n",
       "  Tensor[UByte, [28, 28, 1]],\n",
       "  Tensor[UByte, [28, 28, 1]],\n",
       "  Tensor[UByte, [28, 28, 1]],\n",
       "  Tensor[UByte, [28, 28, 1]]\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sess = Session()\n",
    "def showImage(image: Tensor[UByte]): Unit = {\n",
    "  val exampleImage = tf.decodeRaw[Byte](tf.image.encodePng(image))\n",
    "  val png = sess.run(fetches = exampleImage)\n",
    "  Image(png.entriesIterator.toArray).withFormat(Image.PNG).withWidth(50).display()\n",
    "}\n",
    "\n",
    "val randomImages = for {\n",
    "  index <- (0 to 4).map(_ => Random.nextInt(dataset.testImages.shape(0)))\n",
    "  image = dataset.testImages(index).expandDims(-1)\n",
    "} yield image\n",
    "randomImages.foreach(showImage(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainImages\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = Dataset[TensorSlicesDataset]\n",
       "\u001b[36mtrainLabels\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]] = Dataset[TensorSlicesDataset]\n",
       "\u001b[36mtrainData\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mDataset\u001b[39m[(\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m])] = Dataset[TensorSlicesDataset/Zip/Repeat/Shuffle/Batch/Prefetch]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Load and batch data using pre-fetching.\n",
    "val trainImages = tf.data.datasetFromTensorSlices(dataset.trainImages.toFloat)\n",
    "val trainLabels = tf.data.datasetFromTensorSlices(dataset.trainLabels.toLong)\n",
    "val trainData =\n",
    "  trainImages.zip(trainLabels)\n",
    "      .repeat()\n",
    "      .shuffle(10000)\n",
    "      .batch(256)\n",
    "      .prefetch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36minput\u001b[39m: \u001b[32mInput\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = org.platanios.tensorflow.api.learn.layers.Input@24eac06\n",
       "\u001b[36mtrainInput\u001b[39m: \u001b[32mInput\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]] = org.platanios.tensorflow.api.learn.layers.Input@7dec458b\n",
       "\u001b[36mlayer\u001b[39m: \u001b[32mCompose\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = \u001b[33mCompose\u001b[39m(\n",
       "  \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "  \u001b[33mCompose\u001b[39m(\n",
       "    \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "    \u001b[33mCompose\u001b[39m(\n",
       "      \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "      \u001b[33mCompose\u001b[39m(\n",
       "        \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "        \u001b[33mCompose\u001b[39m(\n",
       "          \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "          \u001b[33mCompose\u001b[39m(\n",
       "            \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "            \u001b[33mCompose\u001b[39m(\n",
       "              \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "              \u001b[33mFlatten\u001b[39m(\u001b[32m\"Input/Flatten\"\u001b[39m),\n",
       "              \u001b[33mLinear\u001b[39m(\n",
       "                \u001b[32m\"Layer_0\"\u001b[39m,\n",
       "                \u001b[32m128\u001b[39m,\n",
       "                true,\n",
       "                \u001b[33mRandomNormalInitializer\u001b[39m(\n",
       "                  Tensor[Float, []],\n",
       "                  Tensor[Float, []],\n",
       "                  \u001b[32mNone\u001b[39m\n",
       "                ),\n",
       "                \u001b[33mRandomNormalInitializer\u001b[39m(\n",
       "                  Tensor[Float, []],\n",
       "                  Tensor[Float, []],\n",
       "                  \u001b[32mNone\u001b[39m\n",
       "                )\n",
       "              )\n",
       "            ),\n",
       "            \u001b[33mReLU\u001b[39m(\u001b[32m\"Layer_0/Activation\"\u001b[39m, \u001b[32m0.1F\u001b[39m)\n",
       "          ),\n",
       "          \u001b[33mLinear\u001b[39m(\n",
       "            \u001b[32m\"Layer_1\"\u001b[39m,\n",
       "            \u001b[32m64\u001b[39m,\n",
       "            true,\n",
       "            \u001b[33mRandomNormalInitializer\u001b[39m(Tensor[Float, []], Tensor[Float, []], \u001b[32mNone\u001b[39m),\n",
       "            \u001b[33mRandomNormalInitializer\u001b[39m(Tensor[Float, []], Tensor[Float, []], \u001b[32mNone\u001b[39m)\n",
       "...\n",
       "\u001b[36mloss\u001b[39m: \u001b[32mCompose\u001b[39m[(\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]), \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = \u001b[33mCompose\u001b[39m(\n",
       "  \u001b[32m\"Loss\"\u001b[39m,\n",
       "  \u001b[33mSparseSoftmaxCrossEntropy\u001b[39m(\u001b[32m\"Loss\"\u001b[39m),\n",
       "  \u001b[33mMean\u001b[39m(\u001b[32m\"Loss/Mean\"\u001b[39m, \u001b[32mnull\u001b[39m, false)\n",
       ")\n",
       "\u001b[36moptimizer\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mtraining\u001b[39m.\u001b[32moptimizers\u001b[39m.\u001b[32mGradientDescent\u001b[39m = org.platanios.tensorflow.api.ops.training.optimizers.GradientDescent@6aca6d9f\n",
       "\u001b[36mmodel\u001b[39m: \u001b[32mSupervisedTrainableModel\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mFloat\u001b[39m] = org.platanios.tensorflow.api.learn.Model$$anon$1@fe85c89"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create the MLP model.\n",
    "val input = Input(FLOAT32, Shape(-1, 28, 28))\n",
    "val trainInput = Input(INT64, Shape(-1))\n",
    "val layer = Flatten[Float](\"Input/Flatten\") >>\n",
    "    Linear[Float](\"Layer_0\", 128) >> ReLU[Float](\"Layer_0/Activation\", 0.1f) >>\n",
    "    Linear[Float](\"Layer_1\", 64) >> ReLU[Float](\"Layer_1/Activation\", 0.1f) >>\n",
    "    Linear[Float](\"Layer_2\", 32) >> ReLU[Float](\"Layer_2/Activation\", 0.1f) >>\n",
    "    Linear[Float](\"OutputLayer\", 10)\n",
    "val loss = SparseSoftmaxCrossEntropy[Float, Long, Float](\"Loss\") >>\n",
    "    Mean(\"Loss/Mean\")\n",
    "val optimizer = tf.train.GradientDescent(1e-6f)\n",
    "val model = Model.simpleSupervised(input, trainInput, layer, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.hooks._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.config.TensorBoardConfig\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mloss\u001b[39m: \u001b[32mCompose\u001b[39m[(\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]), \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = \u001b[33mCompose\u001b[39m(\n",
       "  \u001b[32m\"Loss\"\u001b[39m,\n",
       "  \u001b[33mCompose\u001b[39m(\n",
       "    \u001b[32m\"Loss\"\u001b[39m,\n",
       "    \u001b[33mSparseSoftmaxCrossEntropy\u001b[39m(\u001b[32m\"Loss\"\u001b[39m),\n",
       "    \u001b[33mMean\u001b[39m(\u001b[32m\"Loss/Mean\"\u001b[39m, \u001b[32mnull\u001b[39m, false)\n",
       "  ),\n",
       "  \u001b[33mScalarSummary\u001b[39m(\n",
       "    \u001b[32m\"Loss\"\u001b[39m,\n",
       "    \u001b[32m\"Loss\"\u001b[39m,\n",
       "    \u001b[32mnull\u001b[39m,\n",
       "    \u001b[33mSet\u001b[39m(org.platanios.tensorflow.api.core.Graph$Keys$SUMMARIES$@5ed9cf9e)\n",
       "  )\n",
       ")\n",
       "\u001b[36msummariesDir\u001b[39m: \u001b[32mjava\u001b[39m.\u001b[32mnio\u001b[39m.\u001b[32mfile\u001b[39m.\u001b[32mPath\u001b[39m = tmp/summaries\n",
       "\u001b[36mestimator\u001b[39m: \u001b[32mInMemoryEstimator\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], (\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]), \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mFloat\u001b[39m, (\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], (\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]))] = org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator@2f529710"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.platanios.tensorflow.api.learn.hooks._\n",
    "import org.platanios.tensorflow.api.config.TensorBoardConfig\n",
    "\n",
    "val loss = SparseSoftmaxCrossEntropy[Float, Long, Float](\"Loss\") >>\n",
    "    Mean(\"Loss/Mean\") >>\n",
    "    ScalarSummary(name = \"Loss\", tag = \"Loss\")\n",
    "val summariesDir = Paths.get(\"tmp/summaries\")\n",
    "val estimator = InMemoryEstimator(\n",
    "  modelFunction = model,\n",
    "  configurationBase = Configuration(Some(summariesDir)),\n",
    "  trainHooks = Set(\n",
    "    SummarySaver(summariesDir, StepHookTrigger(100)),\n",
    "    CheckpointSaver(summariesDir, StepHookTrigger(1000))),\n",
    "  tensorBoardConfig = TensorBoardConfig(summariesDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-25 22:12:19.315 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 0.\n",
      "2018-11-25 22:12:19.317 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-0'.\n",
      "2018-11-25 22:12:24.316 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-0'.\n",
      "2018-11-25 22:12:27.875 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 1000.\n",
      "2018-11-25 22:12:27.876 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-1000'.\n",
      "2018-11-25 22:12:28.805 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-1000'.\n",
      "2018-11-25 22:12:33.241 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 2000.\n",
      "2018-11-25 22:12:33.242 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-2000'.\n",
      "2018-11-25 22:12:34.679 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-2000'.\n",
      "2018-11-25 22:12:38.452 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 3000.\n",
      "2018-11-25 22:12:38.452 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-3000'.\n",
      "2018-11-25 22:12:39.675 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-3000'.\n",
      "2018-11-25 22:12:45.426 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 4000.\n",
      "2018-11-25 22:12:45.427 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-4000'.\n",
      "2018-11-25 22:12:46.311 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-4000'.\n",
      "2018-11-25 22:12:50.535 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 5000.\n",
      "2018-11-25 22:12:50.536 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-5000'.\n",
      "2018-11-25 22:12:51.376 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-5000'.\n",
      "2018-11-25 22:12:54.788 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 6000.\n",
      "2018-11-25 22:12:54.789 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-6000'.\n",
      "2018-11-25 22:12:55.616 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-6000'.\n",
      "2018-11-25 22:13:00.133 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 7000.\n",
      "2018-11-25 22:13:00.136 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-7000'.\n",
      "2018-11-25 22:13:01.684 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-7000'.\n",
      "2018-11-25 22:13:05.769 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 8000.\n",
      "2018-11-25 22:13:05.770 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-8000'.\n",
      "2018-11-25 22:13:06.706 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-8000'.\n",
      "2018-11-25 22:13:09.755 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 9000.\n",
      "2018-11-25 22:13:09.756 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-9000'.\n",
      "2018-11-25 22:13:10.888 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-9000'.\n",
      "2018-11-25 22:13:13.829 [scala-interpreter-1] INFO  Learn / Hooks / Checkpoint Saver - Saving checkpoint for step 10000.\n",
      "2018-11-25 22:13:13.829 [scala-interpreter-1] INFO  Variables / Saver - Saving parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-10000'.\n",
      "2018-11-25 22:13:14.605 [scala-interpreter-1] INFO  Variables / Saver - Saved parameters to '/Users/brunksn/repos/my/almond-examples/tmp/summaries/model.ckpt-10000'.\n"
     ]
    }
   ],
   "source": [
    "estimator.train(() => trainData, StopCriteria(maxSteps = Some(10000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVQokWNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kI4JvP8AAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 7"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA70lEQVQokWNgoAlgRDBLOPVCGKYfX4xN2cq/f//+/fv3lhxCiBkuF8LAcGPpa3Wht4cx9Jn8+ntJgYeB7dzfHkxDfX9fkmRgYKj68dcRi5XyQgwMDAwX/2KVZGBgYGAo/f73GBcOOZ/vf5/bI/GZUFzFxrDyIA6NG779nc+DQ07y1d+Xyrhcc+zv315ccn4//u7FZajwCTwa2/7+XYtLI8OPv38l0cVYkNhCvxkYGD7+ZuVnECxkYPhb/g1Z8hIDAwPD6ufi4RDui1Z4Sljnj1D15x/DpjMMR44jkkkZKwODdjgDw7wHDOuu43LZAAMAWllQaMgkNq4AAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 2"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAjklEQVQokWNgoD9gRhdQe/3uFIzNhC5p+O8pbqPaP+KW0/0yDcFBN1adayVunafuc+OUU/h3A4mHZqw9w2vckroMXThNtXx7lgOnTmehGz9wSur/X4PTVIkX11H4KDoTxE7glpRneI/TVIYn/5xw6rQVx62PofffWdS4R9LJ5cWw5i8ujazHNnDhMZdOAABQEyD7KdJU1AAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 1"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA8klEQVQokcXQMUtCURgG4NdjQuiaQ8u9gYg/wEEI0jEd/CEhCv6AQEdBRBCa+wM1OtXUov2BKDQo4gqu0vTyosPtlp5zW/Wb3nOecz74PuDAlbnRs/8f5kk1ts5mK2dvrcfJv9i6PgcS36fHHzFNRZIiZ0XXxmtJWr5LcqwyF8lRvdwhryw7W1Cc9dKAH3DVTjlTPJwAAJoUczZOvTD6kwh/5zSm9BmmhDGmu/OzT0bRbfsaYbayoAIvHock5xdhPrJGGhcAvDztXr5JtdqXtFbMhtpktFuObPSDHwwec2kbUR6E2HAEAFC9591l1YvHvdUGJJOAOqgBKmsAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 0"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2klEQVQokWNgGLzA6AGU4SYLZTAhJN3ZoQy/bgxJFi8Y64wWN7qko+V8KEtIiwvNRt03N3mgzAN/RNEkV3w3hWn8/xdNMuTTZRiz9+9eVlTJlX+yoCyFF7+cUOX4H/6BMdv+wM2AupZdegVMRJnhCppzOM9cFIKwxP7+zYaJskCo73eDt/YxMDDoKMv/Z/iPppNBc9XXP3/+/Hnx/PefP5wwQUa4tKEyAwPDGoaF0TDTsID6P3900exEAEZGhss4Jf8jOYcJXZKD4QdOKxlevMnHLbnZCbcclQAA/k48HXOpiTkAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 9"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAoklEQVQokWNgGGSAGV3A98abc/9xKBZ+/O8fJy6TAv/9W8qIQ4799L9/nrg0mv779wvBY0IzlYFhFy6NDEf+/TDAJWf1799bJC6qsaYMDNNxmrr43zsZXHI2f/7dR+ajGCvMxLAbn6mmuORk/vy7hCKAbKwVE8NGnKZm/nslglOnG8Ojj7gkWVUYfvzGJfnvNMMdVHuQksn/04JnT+N0EBUBABoMMeI4qlfqAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 1"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA30lEQVQokWNgGGSAGc4S26p29wOUze92/x+yKsHXv1bC2Px3Pqoiy4ns/TsZzun+m4JivNvfv6Iwtva/tbzIcmIz/ybA5Z7/i0HRuPj/GW4YO+PfPFRHL/q7iRXC4mx++xcmygJjeO/6MJ2BgcHewYJhDapGBuMnf//++/v3799/f//eVkbTeVbXwKP09UIGhsUXGY7dZcABlP6dE8Ulx7DgrytOudB/H41wSs77txSnHMPzL7g1Zvx7gVvjhb9zGXjl4FwmNOm/0fubcer893eWLA5J230N4my4baUSAAD1ME6TqA5rBAAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 9"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2klEQVQokWNgGKqAb+pBVlxy0Q/+/hXGISfz+t/fv8uEsEtO+Pvv79+/74rZsMjJf/x7Yeffv3+fS2CR9P93kIEj6fa//ycRJjPBGOz/+xl+zLv9//+3X5iSkQzeDAwMJgwMJ75gGhv294JG6LLfb/+90cKUFHr399/fvztVbvydgcVFLh/+/5vIwdD2774yNtl5fTwMDJzr/y7EIgkFEX8fwTzDjCF5Td3y+0GcWg2+/lXDpZPhxU83qc1/cGkVvfVPD7eb5P4txS3JsOsLlmCCAb77fni0EgEARxFUnCmnzVwAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 9"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7UlEQVQokWNgoD9gxhARVJeQ+FkpyvoSU7H3zJt///69/u3vX3QZ5b4vf/7CAAMDAwuypEw+hL5xFULDJUUKjuz49fEr964rJ89//4pqIve5v34MDAoMckyY7mDb+LeFC4eHeFr/vuTHIccQ8/e+DBZhiBVWDOefYJGEhNB8LkWWTy8wJBkZGBgYGP7/Y2D4N+OE3J2rDNrH0c3o/osAL1agG256695vmOyfGkzbnT1OQGXXY/NQxd+fM4yX4JA0+vv3754/f/9OwSbJufzv379/f63nxibJIL7l+d+7DVilGBgYGGKniuGUow8AAK1edM1OQ1sFAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 2"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABBElEQVQokd3QsS8DcRjG8UcOPUFiINLNYGgj2M7QpTGISSIxWRkMFomIGESCwWJ1XTtYDP4Ag60xoqNBqjW0IWlPQ/Tc9wyWa/P7/QOe7c3nfYb3lf5N+rqm6fHVPH7pybA46zcA6JQvBntortCE6uVpeMdrZavbCg24OXel20zp8zmaSJB7GFE/Gpakx5klIInLH9Q8SXKmdisBcXFAkvr/0IkULqxl9JXNvk1K9ZMw0Ry6bkcxhAD8XKV77hzbz72/pOY9Sf5B0/iTIrQ2HCNprwPrZtJmAOWU2bwWBDlL8RjaeYuNfoNvsZEa3LsWXIlh0WJ6gDObqRrX01bcibetZsovhERycoR1WsYAAAAASUVORK5CYII="
     },
     "metadata": {
      "width": 50
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 9"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mimages\u001b[39m: \u001b[32mTensor\u001b[39m[\u001b[32mUByte\u001b[39m] = Tensor[UByte, [10, 28, 28]]\n",
       "\u001b[36mresult\u001b[39m: \u001b[32mTensor\u001b[39m[\u001b[32mFloat\u001b[39m] = Tensor[Float, [10, 10]]\n",
       "\u001b[36mpredictedClasses\u001b[39m: \u001b[32mTensor\u001b[39m[\u001b[32mLong\u001b[39m] = Tensor[Long, [10]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val images = dataset.testImages(0::10)\n",
    "val result = estimator.infer(() => images.toFloat)\n",
    "val predictedClasses = result.argmax(1)\n",
    "for (i <- 0 until images.shape(0)) {\n",
    "    showImage(images(i).expandDims(-1))\n",
    "    print(\"predicted class: \")\n",
    "    print(predictedClasses(i).scalar)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.12)",
   "language": "scala",
   "name": "scala212"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
